{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, Binarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score,confusion_matrix\n",
    "\n",
    "# Miscellaneous\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('Dataset\\survey.csv')\n",
    "\n",
    "# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n",
    "numeric_features = ['Age']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    # Add binning here\n",
    "    ('binarizer', Binarizer(threshold=35))\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them)\n",
    "categorical_features = ['Gender', 'Country', 'state', 'self_employed', 'family_history',\n",
    "                       'work_interfere', 'no_employees', 'remote_work', 'tech_company', 'benefits',\n",
    "                       'care_options', 'wellness_program', 'seek_help', 'anonymity', 'leave',\n",
    "                       'mental_health_consequence', 'phys_health_consequence', 'coworkers',\n",
    "                       'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "                       'mental_vs_physical', 'obs_consequence']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Add PCA to the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    # Add PCA here\n",
    "    # ('pca', TruncatedSVD(n_components=20))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "data_transformed = pipeline.fit_transform(data.drop(columns=['treatment'],axis=1))\n",
    "le = LabelEncoder()\n",
    "label_transformed = le.fit_transform(data['treatment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocesor.pkl','wb') as file:\n",
    "    pickle.dump(pipeline,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression...\n",
      "Best score for LogisticRegression: 0.8410953506698187\n",
      "Evaluating DecisionTreeClassifier...\n",
      "Best score for DecisionTreeClassifier: 0.8357930879207475\n",
      "Evaluating KNeighborsClassifier...\n",
      "Best score for KNeighborsClassifier: 0.7383372734436564\n",
      "Evaluating RandomForestClassifier...\n",
      "Best score for RandomForestClassifier: 0.8389733198243837\n",
      "Evaluating AdaBoostClassifier...\n",
      "Best score for AdaBoostClassifier: 0.8326184847461443\n",
      "Evaluating GradientBoostingClassifier...\n",
      "Best score for GradientBoostingClassifier: 0.8347348868625464\n",
      "Evaluating XGBClassifier...\n",
      "Best score for XGBClassifier: 0.8421479229989869\n",
      "Best model: DecisionTreeClassifier\n",
      "Best score: 0.819047619047619\n",
      "Best report: {'accuracy': 0.819047619047619, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.93      0.69      0.79       158\\n           1       0.75      0.95      0.84       157\\n\\n    accuracy                           0.82       315\\n   macro avg       0.84      0.82      0.82       315\\nweighted avg       0.84      0.82      0.82       315\\n', 'auc': 0.8194590018543901, 'confusion_matrix': array([[109,  49],\n",
      "       [  8, 149]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_transformed, label_transformed, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the hyperparameter search space for each model\n",
    "hyperparameter_spaces = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"C\": np.logspace(-5, 5, 10),\n",
    "        \"penalty\": [\"l2\", \"none\"],  # Change this line\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 5],\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 500, 1000],\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 5],\n",
    "    },\n",
    "    \"AdaBoostClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 500, 1000],\n",
    "        \"learning_rate\": [0.1, 0.5, 1.0],\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 500, 1000],\n",
    "        \"learning_rate\": [0.1, 0.5, 1.0],\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"n_estimators\": [100, 200, 500, 1000],\n",
    "        \"learning_rate\": [0.1, 0.5, 1.0],\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning for each model\n",
    "best_model, best_score, best_report = None, 0, None\n",
    "for model_name, hyperparameter_space in hyperparameter_spaces.items():\n",
    "    print(f\"Evaluating {model_name}...\")  # Add this line\n",
    "    model = eval(model_name)()\n",
    "    grid_search = GridSearchCV(model, hyperparameter_space, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print the best score of the current model\n",
    "    print(f\"Best score for {model_name}: {grid_search.best_score_}\")  # Add this line\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # If this model is better than the previous best_model, update best_model and best_report\n",
    "    if accuracy > best_score:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_score = accuracy\n",
    "        best_report = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"classification_report\": classification_rep,\n",
    "            \"auc\": auc_score,\n",
    "            \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "        }\n",
    "\n",
    "# Print the test results for the best model\n",
    "print(\"Best model:\", type(best_model).__name__)\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Best report:\", best_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to a pickle file\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessor and model from the pickle files\n",
    "with open('preprocesor.pkl', 'rb') as file:\n",
    "    preprocessor = pickle.load(file)\n",
    "\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "def test_predict():\n",
    "    # Create a new data point\n",
    "    new_data = pd.DataFrame({\n",
    "        \"Timestamp\": [\"2023-10-10 12:00:00\"],\n",
    "        \"Age\": [35],\n",
    "        \"Gender\": [\"Male\"],\n",
    "        \"Country\": [\"United States\"],\n",
    "        \"state\": [\"CA\"],\n",
    "        \"self_employed\": [False],\n",
    "        \"family_history\": [True],\n",
    "        \"treatment\": [\"Yes\"],\n",
    "        \"work_interfere\": [\"Sometimes\"],\n",
    "        \"no_employees\": [26-100],\n",
    "        \"remote_work\": [True],\n",
    "        \"tech_company\": [True],\n",
    "        \"benefits\": [True],\n",
    "        \"care_options\": [True],\n",
    "        \"wellness_program\": [True],\n",
    "        \"seek_help\": [True],\n",
    "        \"anonymity\": [True],\n",
    "        \"leave\": [True],\n",
    "        \"mental_health_consequence\": [True],\n",
    "        \"phys_health_consequence\": [True],\n",
    "        \"coworkers\": [\"Yes\"],\n",
    "        \"supervisor\": [\"Yes\"],\n",
    "        \"mental_health_interview\": [\"Yes\"],\n",
    "        \"phys_health_interview\": [\"Yes\"],\n",
    "        \"mental_vs_physical\": [\"No\"],\n",
    "        \"obs_consequence\": [\"No\"]\n",
    "    })\n",
    "\n",
    "    # Preprocess the new data\n",
    "    new_data_transformed = preprocessor.transform(new_data.drop(columns=['treatment'],axis=1))\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(new_data_transformed)[0]\n",
    "    print(prediction)\n",
    "\n",
    "    # Assert that the prediction is 1 (for treatment)\n",
    "    assert prediction == 1, f\"Expected 1, but got {prediction}\"\n",
    "\n",
    "\n",
    "test_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
